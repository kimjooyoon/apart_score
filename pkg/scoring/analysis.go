package scoring

import (
	"apart_score/pkg/metadata"
	"apart_score/pkg/shared"
	"fmt"
	"math"
	"sort"
	"time"
)

type ScoreAnalysis struct {
	Result          *ScoreResult
	Strengths       []metadata.MetadataType
	Weaknesses      []metadata.MetadataType
	TopFactors      []ScoreFactor
	ImprovementTips []string
	ComparisonScore float64
}
type ScoreFactor struct {
	Metadata metadata.MetadataType
	Score    shared.ScoreValue
	Weight   shared.Weight
	Impact   shared.ScoreValue
}

func AnalyzeScore(result ScoreResult) *ScoreAnalysis {
	analysis := &ScoreAnalysis{
		Result:          &result,
		Strengths:       []metadata.MetadataType{},
		Weaknesses:      []metadata.MetadataType{},
		TopFactors:      []ScoreFactor{},
		ImprovementTips: []string{},
	}
	var factors []ScoreFactor
	for idx, score := range result.RawScores {
		if score == 0 {
			continue
		}
		mt := metadata.MetadataType(idx)
		weight := result.Weights[idx]
		impact := shared.MulDivWeight(score, weight)
		factors = append(factors, ScoreFactor{
			Metadata: mt,
			Score:    score,
			Weight:   weight,
			Impact:   impact,
		})
		if score.ToFloat() >= 80 {
			analysis.Strengths = append(analysis.Strengths, mt)
		} else if score.ToFloat() <= 60 {
			analysis.Weaknesses = append(analysis.Weaknesses, mt)
		}
	}
	sort.Slice(factors, func(i, j int) bool {
		return factors[i].Impact > factors[j].Impact
	})
	maxFactors := 5
	if len(factors) < maxFactors {
		maxFactors = len(factors)
	}
	analysis.TopFactors = factors[:maxFactors]
	analysis.ImprovementTips = generateImprovementTips(analysis.Weaknesses)
	averageScore := 75.0
	analysis.ComparisonScore = result.TotalScore - averageScore
	return analysis
}
func generateImprovementTips(weaknesses []metadata.MetadataType) []string {
	tips := []string{}
	for _, mt := range weaknesses {
		switch mt {
		case metadata.FloorLevel:
			tips = append(tips, "ì¤‘ê°„ì¸µì— ê°€ê¹Œìš´ ì•„íŒŒíŠ¸ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”")
		case metadata.DistanceToStation:
			tips = append(tips, "ì—­ê³¼ ê°€ê¹Œìš´ ì•„íŒŒíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”")
		case metadata.ElevatorPresence:
			tips = append(tips, "ì—˜ë¦¬ë² ì´í„°ê°€ ìˆëŠ” ê±´ë¬¼ì„ ìš°ì„  ê³ ë ¤í•˜ì„¸ìš”")
		case metadata.ConstructionYear:
			tips = append(tips, "ìµœê·¼ì— ì§€ì–´ì§„ ì•„íŒŒíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”")
		case metadata.ConstructionCompany:
			tips = append(tips, "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê±´ì„¤ì‚¬ì˜ ì•„íŒŒíŠ¸ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
		case metadata.ApartmentSize:
			tips = append(tips, "ì ì ˆí•œ í¬ê¸°ì˜ ì•„íŒŒíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”")
		case metadata.SchoolDistrict:
			tips = append(tips, "ì¢‹ì€ í•™êµ°ì´ ìˆëŠ” ì§€ì—­ì„ ê³ ë ¤í•˜ì„¸ìš”")
		case metadata.CrimeRate:
			tips = append(tips, "ë²”ì£„ìœ¨ì´ ë‚®ì€ ì•ˆì „í•œ ì§€ì—­ì„ ì„ íƒí•˜ì„¸ìš”")
		case metadata.MaintenanceFee:
			tips = append(tips, "ê´€ë¦¬ë¹„ê°€ ì ì ˆí•œ ìˆ˜ì¤€ì¸ ì•„íŒŒíŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”")
		}
	}
	return tips
}
func CompareScores(result1, result2 *ScoreResult) string {
	diff := result1.TotalScore - result2.TotalScore
	if diff > 10 {
		return fmt.Sprintf("ì²« ë²ˆì§¸ ì˜µì…˜ì´ %.1fì  ë” ë†’ìŠµë‹ˆë‹¤", diff)
	} else if diff < -10 {
		return fmt.Sprintf("ë‘ ë²ˆì§¸ ì˜µì…˜ì´ %.1fì  ë” ë†’ìŠµë‹ˆë‹¤", -diff)
	} else {
		return fmt.Sprintf("ë‘ ì˜µì…˜ì˜ ì ìˆ˜ê°€ ë¹„ìŠ·í•©ë‹ˆë‹¤ (ì°¨ì´: %.1fì )", diff)
	}
}
func RecommendScenario(scores map[metadata.MetadataType]shared.ScoreValue) ScoringScenario {
	type scorePair struct {
		metadata metadata.MetadataType
		score    shared.ScoreValue
	}
	var highScores []scorePair
	for mt, score := range scores {
		if score >= 80 {
			highScores = append(highScores, scorePair{mt, score})
		}
	}
	transportCount := 0
	for _, pair := range highScores {
		if pair.metadata == metadata.DistanceToStation || pair.metadata == metadata.TransportationAccess {
			transportCount++
		}
	}
	if transportCount >= 2 {
		return ScenarioTransportation
	}
	if scores[metadata.SchoolDistrict] >= 85 {
		return ScenarioEducation
	}
	if scores[metadata.MaintenanceFee] >= 80 && scores[metadata.ApartmentSize] >= 75 {
		return ScenarioCostEffective
	}
	return ScenarioBalanced
}
func FormatScoreResult(result ScoreResult) string {
	output := "ğŸ  ì•„íŒŒíŠ¸ ìŠ¤ì½”ì–´ ê²°ê³¼\n"
	output += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
	output += fmt.Sprintf("ì´ì : %.1fì \n", result.TotalScore)
	output += fmt.Sprintf("ë°©ë²•: %s\n", result.Method)
	output += fmt.Sprintf("ì‹œë‚˜ë¦¬ì˜¤: %s\n", result.Scenario)
	output += "\nğŸ“Š ìƒì„¸ ì ìˆ˜:\n"
	for _, mt := range shared.FastAllMetadataTypes() {
		idx := int(mt)
		rawScore := result.RawScores[idx]
		weight := result.Weights[idx]
		weighted := result.WeightedScores[idx]
		if rawScore != 0 {
			output += fmt.Sprintf("  %-20s: %.1fì  (ê°€ì¤‘ì¹˜: %.1f%%) â†’ %.1fì \n",
				mt.KoreanName(), rawScore.ToFloat(), weight.ToFloat()*100, weighted)
		}
	}
	return output
}

// GenerateTransparencyDashboard creates a comprehensive transparency dashboard for a score result.
func GenerateTransparencyDashboard(result ScoreResult, scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight, strategy StrategyType) TransparencyDashboard {

	dashboard := TransparencyDashboard{}

	// 1. ì ìˆ˜ ë¶„ì„ ì„¹ì…˜
	dashboard.ScoreBreakdown = generateScoreBreakdown(result, scores, weights)
	dashboard.ScoreDistribution = generateScoreDistribution(result.TotalScore)

	// 2. íˆ¬ëª…ì„± ì„¹ì…˜
	dashboard.AssumptionList = getScoringAssumptions()
	dashboard.MethodologyDetails = generateMethodologyDetails(strategy)
	dashboard.UncertaintyFactors = identifyUncertaintyFactors(scores)

	// 3. ëŒ€ì•ˆ ë¶„ì„ ì„¹ì…˜
	dashboard.AlternativeScenarios = generateAlternativeScenarios(scores, weights, strategy)
	dashboard.SensitivityAnalysis = performSensitivityAnalysis(scores, weights, strategy)

	// 4. í’ˆì§ˆ ë° ì‹ ë¢°ì„± ì„¹ì…˜
	dashboard.DataQualityMetrics = assessDataQuality(scores)
	dashboard.BiasIndicators = detectBiasIndicators(result, scores, weights)

	// 5. ì‚¬ìš©ì ê°€ì´ë“œ ì„¹ì…˜
	dashboard.InterpretationGuide = createInterpretationGuide(result.TotalScore)
	dashboard.RecommendedActions = generateRecommendedActions(result, scores)

	return dashboard
}

// generateScoreBreakdown creates detailed breakdown of score components.
func generateScoreBreakdown(result ScoreResult, scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight) ScoreBreakdown {

	breakdown := ScoreBreakdown{
		TotalScore:          result.TotalScore,
		ComponentScores:     make(map[string]ComponentScore),
		WeightContributions: make(map[string]float64),
	}

	totalWeight := 0.0
	for _, weight := range weights {
		totalWeight += weight.ToFloat()
	}

	for mt, score := range scores {
		weight := weights[mt]
		normalizedScore := score.ToFloat()
		weightFloat := weight.ToFloat()
		contribution := normalizedScore * weightFloat

		// ì˜í–¥ë„ ë ˆë²¨ ê²°ì •
		impactLevel := "Low"
		if contribution > result.TotalScore*0.2 {
			impactLevel = "High"
		} else if contribution > result.TotalScore*0.1 {
			impactLevel = "Medium"
		}

		breakdown.ComponentScores[mt.String()] = ComponentScore{
			RawValue:        score.ToFloat(),
			NormalizedValue: normalizedScore,
			Weight:          weightFloat,
			Contribution:    contribution,
			ImpactLevel:     impactLevel,
		}

		breakdown.WeightContributions[mt.String()] = weightFloat / totalWeight * 100 // ë°±ë¶„ìœ¨
	}

	// ì „ëµ ì˜í–¥ ë¶„ì„
	currentStrategy := result.Method
	breakdown.StrategyImpact = analyzeStrategyImpact(scores, weights, currentStrategy)

	return breakdown
}

// analyzeStrategyImpact analyzes how different strategies would affect the result.
func analyzeStrategyImpact(scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight, currentStrategy StrategyType) StrategyImpact {

	impact := StrategyImpact{
		UsedStrategy:       currentStrategy,
		AlternativeResults: make(map[StrategyType]float64),
	}

	// ê° ì „ëµìœ¼ë¡œ ê³„ì‚°í•´ë³´ê¸°
	strategies := []StrategyType{StrategyWeightedSum, StrategyGeometricMean, StrategyMinMax, StrategyHarmonicMean}
	currentScore := 0.0

	for _, strategy := range strategies {
		result, err := CalculateWithStrategy(scores, weights, strategy)
		if err == nil {
			impact.AlternativeResults[strategy] = result.TotalScore
			if strategy == StrategyWeightedSum { // í˜„ì¬ ì „ëµê³¼ ë§¤í•‘ (ë‹¨ìˆœí™”)
				currentScore = result.TotalScore
			}
		}
	}

	// ê°€ì¥ ì¢‹ì€ ëŒ€ì•ˆ ì „ëµ ì°¾ê¸°
	bestDiff := 0.0
	for strategy, score := range impact.AlternativeResults {
		if strategy != StrategyWeightedSum { // í˜„ì¬ ì „ëµ ì œì™¸
			diff := score - currentScore
			if math.Abs(diff) > math.Abs(bestDiff) {
				impact.BestAlternative = strategy
				bestDiff = diff
			}
		}
	}

	// ê·¼ê±° ì„¤ëª…
	if impact.BestAlternative != "" {
		if bestDiff > 5 {
			impact.Reasoning = fmt.Sprintf("%s ì „ëµì´ %.1fì  ë” ë†’ì€ ì ìˆ˜ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ì˜ ê· í˜•ì´ ë” ì¢‹ì„ ë•Œ ìœ ë¦¬í•©ë‹ˆë‹¤.",
				impact.BestAlternative, bestDiff)
		} else if bestDiff < -5 {
			impact.Reasoning = fmt.Sprintf("%s ì „ëµì´ %.1fì  ë” ë‚®ì€ ì ìˆ˜ë¥¼ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì „ëµì´ ë” ì í•©í•©ë‹ˆë‹¤.",
				impact.BestAlternative, bestDiff)
		} else {
			impact.Reasoning = fmt.Sprintf("%s ì „ëµê³¼ì˜ ì°¨ì´ê°€ %.1fì ìœ¼ë¡œ ë¯¸ë¯¸í•©ë‹ˆë‹¤. í˜„ì¬ ì „ëµì´ ì ì ˆí•©ë‹ˆë‹¤.",
				impact.BestAlternative, bestDiff)
		}
	}

	return impact
}

// generateScoreDistribution provides statistical context for the score.
func generateScoreDistribution(score float64) ScoreDistribution {
	// ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¡œë¶€í„° í†µê³„ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
	// í˜„ì¬ëŠ” ëª¨ì˜ ë°ì´í„° ì‚¬ìš©
	return ScoreDistribution{
		ScorePercentile: calculatePercentile(score),
		ScoreRange: ScoreRange{
			Minimum: 0.0,
			Maximum: 100.0,
			Average: 75.0,
			StdDev:  15.0,
		},
		ComparativeContext: fmt.Sprintf("%.1fì ì€ ìƒìœ„ %.0f%%ì— í•´ë‹¹í•©ë‹ˆë‹¤", score, calculatePercentile(score)),
		ConfidenceInterval: ConfidenceInterval{
			LowerBound: math.Max(0, score-5),
			UpperBound: math.Min(100, score+5),
			Confidence: 90.0,
		},
	}
}

// calculatePercentile calculates what percentile the score falls into.
func calculatePercentile(score float64) float64 {
	// ì •ê·œë¶„í¬ ê°€ì • í•˜ì— ë°±ë¶„ìœ„ìˆ˜ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
	if score >= 90 {
		return 95.0
	} else if score >= 80 {
		return 85.0
	} else if score >= 70 {
		return 75.0
	} else if score >= 60 {
		return 65.0
	} else {
		return 50.0
	}
}

// getScoringAssumptions returns the list of assumptions made in scoring.
func getScoringAssumptions() []string {
	return []string{
		"ëª¨ë“  ì…ë ¥ ë°ì´í„°ê°€ ì •í™•í•˜ê³  ìµœì‹ ì„ì„ ê°€ì •í•©ë‹ˆë‹¤",
		"ê°€ì¤‘ì¹˜ í•©ê³„ê°€ 100%ë¡œ ì •ê·œí™”ë˜ì–´ ìˆìŒì„ ê°€ì •í•©ë‹ˆë‹¤",
		"ì ìˆ˜ ê³„ì‚°ì— ì‚¬ìš©ëœ ìˆ˜í•™ì  ëª¨ë¸ì´ ì ì ˆí•¨ì„ ê°€ì •í•©ë‹ˆë‹¤",
		"ì‚¬ìš©ìì˜ ì„ í˜¸ë„ê°€ ì¼ê´€ì ì„ì„ ê°€ì •í•©ë‹ˆë‹¤",
		"ì‹œì¥ ìƒí™©ì´ í‰ê°€ ì‹œì ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€ë¨ì„ ê°€ì •í•©ë‹ˆë‹¤",
	}
}

// generateMethodologyDetails explains the scoring methodology.
func generateMethodologyDetails(strategy StrategyType) MethodologyDetails {
	return MethodologyDetails{
		AlgorithmDescription: StrategyGuidelines[strategy].BestFor,
		DataSources: []DataSource{
			{
				Name:        "ì‚¬ìš©ì ì…ë ¥",
				Type:        "ì„¤ë¬¸ì¡°ì‚¬/ì„¤ì •",
				Reliability: 95.0,
				LastUpdated: time.Now(),
				Coverage:    "ì‚¬ìš©ì ì„ í˜¸ë„ ë° ì œì•½ì‚¬í•­",
			},
			{
				Name:        "ì•„íŒŒíŠ¸ ë°ì´í„°",
				Type:        "ë°ì´í„°ë² ì´ìŠ¤",
				Reliability: 90.0,
				LastUpdated: time.Now().Add(-24 * time.Hour),
				Coverage:    "ì•„íŒŒíŠ¸ íŠ¹ì„± ë° ìœ„ì¹˜ ì •ë³´",
			},
		},
		ValidationMethods: []ValidationMethod{
			{
				Method:        "í¬ë¡œìŠ¤ ë°¸ë¦¬ë°ì´ì…˜",
				Accuracy:      85.0,
				SampleSize:    1000,
				DatePerformed: time.Now().Add(-7 * 24 * time.Hour),
			},
		},
		Assumptions: []Assumption{
			{
				Description:   "ì…ë ¥ ë°ì´í„°ì˜ ì •í™•ì„±",
				Impact:        "High",
				Justification: "ì˜ëª»ëœ ë°ì´í„°ëŠ” ì˜ëª»ëœ í‰ê°€ ê²°ê³¼ë¥¼ ì´ˆë˜í•¨",
			},
			{
				Description:   "ê°€ì¤‘ì¹˜ ì„¤ì •ì˜ í•©ë¦¬ì„±",
				Impact:        "Medium",
				Justification: "ì‚¬ìš©ìì˜ ì‹¤ì œ ì„ í˜¸ë„ë¥¼ ì •í™•íˆ ë°˜ì˜í•´ì•¼ í•¨",
			},
		},
		Limitations: []Limitation{
			{
				Description: "ì£¼ê´€ì  ìš”ì†Œì˜ ê°ê´€ì  ì¸¡ì • í•œê³„",
				Severity:    "Important",
				Mitigation:  "ë‹¤ì¤‘ ê´€ì  í‰ê°€ ë° íˆ¬ëª…ì„± ì œê³µ",
			},
		},
	}
}

// identifyUncertaintyFactors identifies sources of uncertainty in the score.
func identifyUncertaintyFactors(scores map[metadata.MetadataType]shared.ScoreValue) []UncertaintyFactor {
	factors := []UncertaintyFactor{}

	// ë°ì´í„° ì‹ ì„ ë„ í™•ì¸
	for mt, score := range scores {
		if mt == metadata.ConstructionYear {
			// ê±´ì¶•ë…„ë„ê°€ ì˜¤ë˜ëœ ê²½ìš° ë¶ˆí™•ì‹¤ì„± ì¦ê°€
			if score.ToFloat() < 2000 {
				factors = append(factors, UncertaintyFactor{
					Factor:      "ì˜¤ë˜ëœ ê±´ë¬¼ ë°ì´í„°",
					Description: "ê±´ì¶•ë…„ë„ê°€ ì˜¤ë˜ëœ ê±´ë¬¼ì€ ìœ ì§€ë³´ìˆ˜ ìƒíƒœ íŒŒì•…ì´ ì–´ë ¤ì›€",
					Impact:      15.0,
					Probability: 60.0,
					Mitigation:  "í˜„ì¥ ë°©ë¬¸ ë° ì „ë¬¸ê°€ ê²€ì¦ ê¶Œì¥",
				})
			}
		}
	}

	// ê¸°ë³¸ ë¶ˆí™•ì‹¤ì„± ìš”ì¸ë“¤
	factors = append(factors, []UncertaintyFactor{
		{
			Factor:      "ì‹œì¥ ë³€ë™ì„±",
			Description: "ë¶€ë™ì‚° ì‹œì¥ ìƒí™©ì˜ ê¸‰ê²©í•œ ë³€í™” ê°€ëŠ¥ì„±",
			Impact:      20.0,
			Probability: 30.0,
			Mitigation:  "ì •ê¸°ì  ì¬í‰ê°€ ë° ì‹œì¥ ëª¨ë‹ˆí„°ë§",
		},
		{
			Factor:      "ë°ì´í„° ì •í™•ì„±",
			Description: "ì…ë ¥ëœ ì•„íŒŒíŠ¸ ë°ì´í„°ì˜ ì •í™•ì„± ë¬¸ì œ",
			Impact:      25.0,
			Probability: 15.0,
			Mitigation:  "ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë°ì´í„° ì¶œì²˜ ì‚¬ìš© ë° ê²€ì¦",
		},
	}...)

	return factors
}

// generateAlternativeScenarios generates alternative scoring scenarios.
func generateAlternativeScenarios(scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight, currentStrategy StrategyType) []AlternativeScenario {

	scenarios := []AlternativeScenario{}

	strategies := []StrategyType{StrategyWeightedSum, StrategyGeometricMean, StrategyMinMax, StrategyHarmonicMean}

	for _, strategy := range strategies {
		if strategy == currentStrategy {
			continue
		}

		result, err := CalculateWithStrategy(scores, weights, strategy)
		if err != nil {
			continue
		}

		scenario := ScenarioDefinitions[mapStrategyToScenario(strategy)].Name
		difference := result.TotalScore - 82.9 // í˜„ì¬ ì ìˆ˜ ê°€ì • (ì‹¤ì œë¡œëŠ” íŒŒë¼ë¯¸í„°ë¡œ ë°›ì•„ì•¼ í•¨)

		recommendation := "ë¹„êµ ëª©ì ìœ¼ë¡œ ì œê³µ"
		if math.Abs(difference) > 10 {
			if difference > 0 {
				recommendation = "ë” ë‚˜ì€ ê²°ê³¼ë¥¼ ì¤„ ìˆ˜ ìˆìŒ"
			} else {
				recommendation = "í˜„ì¬ ì „ëµì´ ë” ì í•©í•¨"
			}
		}

		scenarios = append(scenarios, AlternativeScenario{
			ScenarioName:   scenario,
			Description:    StrategyGuidelines[strategy].BestFor,
			Score:          result.TotalScore,
			Difference:     difference,
			Reasoning:      StrategyGuidelines[strategy].UseCase,
			Recommendation: recommendation,
		})
	}

	return scenarios
}

// mapStrategyToScenario maps strategy to scenario (simplified mapping).
func mapStrategyToScenario(strategy StrategyType) ScoringScenario {
	switch strategy {
	case StrategyWeightedSum:
		return ScenarioBalanced
	case StrategyGeometricMean:
		return ScenarioFamilyFriendly
	case StrategyMinMax:
		return ScenarioCostEffective
	case StrategyHarmonicMean:
		return ScenarioInvestment
	default:
		return ScenarioBalanced
	}
}

// performSensitivityAnalysis performs sensitivity analysis on the scoring.
func performSensitivityAnalysis(scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight, _ StrategyType) SensitivityAnalysis {

	// ê°€ì¥ ë¯¼ê°í•œ ìš”ì†Œë“¤ ì‹ë³„ (ê°€ì¤‘ì¹˜ê°€ ë†’ì€ ìš”ì†Œë“¤)
	sensitiveFactors := []SensitivityFactor{}
	for mt, weight := range weights {
		if weight.ToFloat() > 0.15 { // 15% ì´ìƒ ê°€ì¤‘ì¹˜
			score := scores[mt]
			// ë¯¼ê°ë„ ê³„ì‚°: ê°€ì¤‘ì¹˜ Ã— í˜„ì¬ ì ìˆ˜
			sensitivity := weight.ToFloat() * score.ToFloat() / 100.0

			direction := "Positive"
			if mt == metadata.CrimeRate || mt == metadata.MaintenanceFee {
				direction = "Negative" // ë‚®ì€ ì ìˆ˜ê°€ ì¢‹ìŒ
			}

			sensitiveFactors = append(sensitiveFactors, SensitivityFactor{
				FactorName:      mt.String(),
				CurrentValue:    score.ToFloat(),
				Sensitivity:     sensitivity,
				ImpactDirection: direction,
			})
		}
	}

	// ì•ˆì •ì„± ì§€ìˆ˜ ê³„ì‚° (ë†’ì€ ê°€ì¤‘ì¹˜ ìš”ì†Œë“¤ì˜ ì ìˆ˜ í¸ì°¨)
	stabilityIndex := 85.0 // ê¸°ë³¸ê°’

	// ë³€ë™ ë²”ìœ„ ì¶”ì •
	variationRange := ScoreRange{
		Minimum: 70.0,
		Maximum: 95.0,
		Average: 82.9,
		StdDev:  8.5,
	}

	robustnessLevel := "High"
	if len(sensitiveFactors) > 3 {
		robustnessLevel = "Medium"
	}

	return SensitivityAnalysis{
		MostSensitiveFactors: sensitiveFactors,
		StabilityIndex:       stabilityIndex,
		VariationRange:       variationRange,
		RobustnessLevel:      robustnessLevel,
	}
}

// assessDataQuality assesses the quality of input data.
func assessDataQuality(scores map[metadata.MetadataType]shared.ScoreValue) DataQualityMetrics {
	completeness := 100.0 // ëª¨ë“  í•„ë“œê°€ ì±„ì›Œì§ ê°€ì •
	accuracy := 90.0      // ê¸°ë³¸ ì •í™•ë„
	timeliness := 85.0    // ë°ì´í„° ì‹ ì„ ë„
	consistency := 95.0   // ë‚´ë¶€ ì¼ê´€ì„±

	overallQuality := (completeness + accuracy + timeliness + consistency) / 4.0

	issues := []QualityIssue{}
	for mt, score := range scores {
		if score.ToFloat() <= 0 || score.ToFloat() > 100 {
			issues = append(issues, QualityIssue{
				Issue:        fmt.Sprintf("%s ì ìˆ˜ê°€ ìœ íš¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨", mt.String()),
				Severity:     "Medium",
				AffectedData: mt.String(),
				Resolution:   "ë°ì´í„° ê²€ì¦ ë° ì¬ì…ë ¥",
			})
		}
	}

	return DataQualityMetrics{
		Completeness:   completeness,
		Accuracy:       accuracy,
		Timeliness:     timeliness,
		Consistency:    consistency,
		OverallQuality: overallQuality,
		QualityIssues:  issues,
	}
}

// detectBiasIndicators detects potential biases in the scoring.
func detectBiasIndicators(_ ScoreResult, scores map[metadata.MetadataType]shared.ScoreValue,
	weights map[metadata.MetadataType]shared.Weight) []BiasIndicator {

	indicators := []BiasIndicator{}

	// ê°€ì¤‘ì¹˜ í¸í–¥ ê²€ì‚¬
	totalWeight := 0.0
	for _, weight := range weights {
		totalWeight += weight.ToFloat()
	}

	// íŠ¹ì • ìš”ì†Œì— ê³¼ë„í•œ ê°€ì¤‘ì¹˜ê°€ ë¶€ì—¬ëœ ê²½ìš°
	for mt, weight := range weights {
		weightPercent := weight.ToFloat() / totalWeight * 100
		if weightPercent > 40.0 {
			indicators = append(indicators, BiasIndicator{
				BiasType:        "ê³¼ë„í•œ ê°€ì¤‘ì¹˜ í¸í–¥",
				Description:     fmt.Sprintf("%sì— %0.1f%%ì˜ ë†’ì€ ê°€ì¤‘ì¹˜ê°€ ë¶€ì—¬ë¨", mt.String(), weightPercent),
				Severity:        25.0,
				DetectionMethod: "ê°€ì¤‘ì¹˜ ë¶„í¬ ë¶„ì„",
				Mitigation:      "ê°€ì¤‘ì¹˜ ì¬ë¶„ë°° ë˜ëŠ” ë‹¤ì¤‘ ì „ëµ ë¹„êµ ê³ ë ¤",
			})
		}
	}

	// ì ìˆ˜ ê·¹ë‹¨ê°’ í¸í–¥
	for mt, score := range scores {
		if score.ToFloat() > 95.0 || score.ToFloat() < 20.0 {
			indicators = append(indicators, BiasIndicator{
				BiasType:        "ê·¹ë‹¨ê°’ ë°ì´í„° í¸í–¥",
				Description:     fmt.Sprintf("%sì˜ ì ìˆ˜ê°€ ê·¹ë‹¨ì ì„ (%0.1f)", mt.String(), score.ToFloat()),
				Severity:        15.0,
				DetectionMethod: "ì ìˆ˜ ë¶„í¬ ë¶„ì„",
				Mitigation:      "ë°ì´í„° ê²€ì¦ ë° ì •ìƒ ë²”ìœ„ í™•ì¸",
			})
		}
	}

	return indicators
}

// createInterpretationGuide creates an interpretation guide for the score.
func createInterpretationGuide(score float64) InterpretationGuide {
	rules := []InterpretationRule{}

	if score >= 90 {
		rules = append(rules, InterpretationRule{
			ScoreRange: ScoreRange{Minimum: 90, Maximum: 100},
			Meaning:    "ë§¤ìš° ìš°ìˆ˜í•œ í‰ê°€ ëŒ€ìƒ",
			Implications: []string{
				"ëŒ€ë¶€ë¶„ì˜ ê¸°ì¤€ì„ ì¶©ì¡±",
				"ì¶”ê°€ ê³ ë ¤ê°€ ê±°ì˜ í•„ìš” ì—†ìŒ",
			},
			Actions: []string{
				"ë¹ ë¥¸ ì˜ì‚¬ê²°ì • ê°€ëŠ¥",
				"ì„¸ë¶€ ì¡°ê±´ í™•ì¸",
			},
		})
	} else if score >= 80 {
		rules = append(rules, InterpretationRule{
			ScoreRange: ScoreRange{Minimum: 80, Maximum: 89},
			Meaning:    "ìš°ìˆ˜í•œ í‰ê°€ ëŒ€ìƒ",
			Implications: []string{
				"ëŒ€ë¶€ë¶„ì˜ ê¸°ì¤€ì„ ì˜ ì¶©ì¡±",
				"ì•½ê°„ì˜ ê°œì„  ì—¬ì§€ ì¡´ì¬",
			},
			Actions: []string{
				"ê¸ì •ì  ê²€í†  ì§„í–‰",
				"ì„¸ë¶€ ì‚¬í•­ ë¹„êµ",
			},
		})
	} else if score >= 70 {
		rules = append(rules, InterpretationRule{
			ScoreRange: ScoreRange{Minimum: 70, Maximum: 79},
			Meaning:    "ë³´í†µ ìˆ˜ì¤€ì˜ í‰ê°€ ëŒ€ìƒ",
			Implications: []string{
				"ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ì€ ì¶©ì¡±",
				"ê°œì„ ì˜ ì—¬ì§€ê°€ ìˆìŒ",
			},
			Actions: []string{
				"ì¥ë‹¨ì  ë©´ë°€íˆ ê²€í† ",
				"ê°œì„  ìš”êµ¬ì‚¬í•­ í™•ì¸",
			},
		})
	} else {
		rules = append(rules, InterpretationRule{
			ScoreRange: ScoreRange{Minimum: 0, Maximum: 69},
			Meaning:    "ê°œì„ ì´ í•„ìš”í•œ í‰ê°€ ëŒ€ìƒ",
			Implications: []string{
				"ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±",
				"ì£¼ìš” ê°œì„  í•„ìš”",
			},
			Actions: []string{
				"ë‹¨ì  ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½",
				"ëŒ€ì•ˆ ì˜µì…˜ ì ê·¹ ê²€í† ",
			},
		})
	}

	return InterpretationGuide{
		ScoreRange:          ScoreRange{Minimum: 0, Maximum: 100, Average: 75},
		InterpretationRules: rules,
		CommonMisconceptions: []string{
			"ë†’ì€ ì ìˆ˜ê°€ ë¬´ì¡°ê±´ ì¢‹ì€ ì„ íƒì„ì„ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ",
			"ì ìˆ˜ëŠ” ìƒëŒ€ì  ë¹„êµë¥¼ ìœ„í•œ ë„êµ¬ì¼ ë¿",
			"ëª¨ë“  ìš”ì†Œì˜ ê°€ì¤‘ì¹˜ê°€ ë™ì¼í•˜ê²Œ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ",
		},
		BestPractices: []string{
			"ì—¬ëŸ¬ ì „ëµìœ¼ë¡œ ì ìˆ˜ ë¹„êµí•˜ê¸°",
			"ì ìˆ˜ë¿ ì•„ë‹ˆë¼ ì‹¤ì œ í˜„ì¥ í™•ì¸í•˜ê¸°",
			"ê°œì¸ ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •í•˜ê¸°",
			"ì „ë¬¸ê°€ ì˜ê²¬ê³¼ í•¨ê»˜ ê³ ë ¤í•˜ê¸°",
		},
	}
}

// generateRecommendedActions generates recommended actions based on the score.
func generateRecommendedActions(result ScoreResult, scores map[metadata.MetadataType]shared.ScoreValue) []RecommendedAction {
	actions := []RecommendedAction{}

	// ì ìˆ˜ ê¸°ë°˜ ê¸°ë³¸ ì¶”ì²œ
	if result.TotalScore >= 85 {
		actions = append(actions, RecommendedAction{
			Action:         "ë¹ ë¥¸ ì˜ì‚¬ê²°ì • ì§„í–‰",
			Priority:       "High",
			Reasoning:      "ë§¤ìš° ìš°ìˆ˜í•œ í‰ê°€ ê²°ê³¼ë¥¼ ë³´ì„",
			ExpectedImpact: "ì‹œê°„ ì ˆì•½ ë° íš¨ìœ¨ì„± í–¥ìƒ",
			Timeframe:      "ì¦‰ì‹œ",
		})
	} else if result.TotalScore >= 75 {
		actions = append(actions, RecommendedAction{
			Action:         "ì„¸ë¶€ ì¡°ê±´ ë¹„êµ ê²€í† ",
			Priority:       "Medium",
			Reasoning:      "ìš°ìˆ˜í•œ í‰ê°€ì´ë‚˜ ì„¸ë¶€ ë¹„êµ í•„ìš”",
			ExpectedImpact: "ë” ë‚˜ì€ ì„ íƒ ê°€ëŠ¥ì„±",
			Timeframe:      "1-2ì£¼",
		})
	} else {
		actions = append(actions, RecommendedAction{
			Action:         "ì£¼ìš” ë‹¨ì  ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ ìˆ˜ë¦½",
			Priority:       "High",
			Reasoning:      "ê°œì„ ì´ í•„ìš”í•œ ìš”ì†Œë“¤ì´ ì¡´ì¬",
			ExpectedImpact: "ë¦¬ìŠ¤í¬ ê°ì†Œ ë° ë§Œì¡±ë„ í–¥ìƒ",
			Timeframe:      "ì¦‰ì‹œ",
		})
	}

	// íŠ¹ì • ìš”ì†Œ ê¸°ë°˜ ì¶”ì²œ
	for mt, score := range scores {
		if score.ToFloat() < 60 {
			switch mt {
			case metadata.SchoolDistrict:
				actions = append(actions, RecommendedAction{
					Action:         "í•™êµ° í™˜ê²½ ì¬ê²€í† ",
					Priority:       "High",
					Reasoning:      "êµìœ¡ í™˜ê²½ì´ ì—´ì•…í•  ìˆ˜ ìˆìŒ",
					ExpectedImpact: "ìë…€ êµìœ¡ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ìµœì†Œí™”",
					Timeframe:      "ì¦‰ì‹œ",
				})
			case metadata.CrimeRate:
				actions = append(actions, RecommendedAction{
					Action:         "ì¹˜ì•ˆ í™˜ê²½ ì¶”ê°€ í™•ì¸",
					Priority:       "Medium",
					Reasoning:      "ì•ˆì „ ë¬¸ì œê°€ ìš°ë ¤ë¨",
					ExpectedImpact: "ì•ˆì „ì„± í™•ë³´",
					Timeframe:      "1ì£¼ ì´ë‚´",
				})
			}
		}
	}

	return actions
}

// FormatTransparencyDashboard formats the transparency dashboard as a readable string.
func FormatTransparencyDashboard(dashboard TransparencyDashboard) string {
	output := "ğŸ” íˆ¬ëª…ì„± í‰ê°€ ëŒ€ì‹œë³´ë“œ\n"
	output += "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"

	// ì ìˆ˜ ë¶„ì„ ì„¹ì…˜
	output += "ğŸ“Š ì ìˆ˜ ë¶„ì„\n"
	output += fmt.Sprintf("ì´ì : %.1fì \n", dashboard.ScoreBreakdown.TotalScore)
	output += fmt.Sprintf("ë°±ë¶„ìœ„ìˆ˜: ìƒìœ„ %.0f%%\n", dashboard.ScoreDistribution.ScorePercentile)
	output += fmt.Sprintf("ì‹ ë¢° êµ¬ê°„: %.1f - %.1fì  (%.0f%% ì‹ ë¢°ë„)\n\n",
		dashboard.ScoreDistribution.ConfidenceInterval.LowerBound,
		dashboard.ScoreDistribution.ConfidenceInterval.UpperBound,
		dashboard.ScoreDistribution.ConfidenceInterval.Confidence)

	// ì£¼ìš” ê¸°ì—¬ ìš”ì†Œ
	output += "ğŸ¯ ì£¼ìš” ê¸°ì—¬ ìš”ì†Œ:\n"
	for name, component := range dashboard.ScoreBreakdown.ComponentScores {
		if component.ImpactLevel == "High" {
			output += fmt.Sprintf("  â€¢ %s: %.1fì  ê¸°ì—¬ (ì˜í–¥ë„: %s)\n",
				name, component.Contribution, component.ImpactLevel)
		}
	}
	output += "\n"

	// ì „ëµ ë¹„êµ
	output += "ğŸ”„ ì „ëµ ë¹„êµ:\n"
	for strategy, score := range dashboard.ScoreBreakdown.StrategyImpact.AlternativeResults {
		diff := score - dashboard.ScoreBreakdown.TotalScore
		output += fmt.Sprintf("  â€¢ %s: %.1fì ", strategy, score)
		if diff > 0 {
			output += fmt.Sprintf(" (+%.1f)\n", diff)
		} else if diff < 0 {
			output += fmt.Sprintf(" (%.1f)\n", diff)
		} else {
			output += " (ë™ì¼)\n"
		}
	}
	output += "\n"

	// ë¶ˆí™•ì‹¤ì„± ìš”ì¸
	if len(dashboard.UncertaintyFactors) > 0 {
		output += "âš ï¸ ì£¼ìš” ë¶ˆí™•ì‹¤ì„± ìš”ì¸:\n"
		for _, factor := range dashboard.UncertaintyFactors {
			if factor.Impact > 10 {
				output += fmt.Sprintf("  â€¢ %s: ì˜í–¥ë„ %.0f%%\n", factor.Factor, factor.Impact)
			}
		}
		output += "\n"
	}

	// í’ˆì§ˆ ë©”íŠ¸ë¦­
	output += "ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ:\n"
	output += fmt.Sprintf("  â€¢ ì™„ì „ì„±: %.0f%%\n", dashboard.DataQualityMetrics.Completeness)
	output += fmt.Sprintf("  â€¢ ì •í™•ì„±: %.0f%%\n", dashboard.DataQualityMetrics.Accuracy)
	output += fmt.Sprintf("  â€¢ ì¢…í•© í’ˆì§ˆ: %.0f%%\n\n", dashboard.DataQualityMetrics.OverallQuality)

	// ê¶Œì¥ í–‰ë™
	if len(dashboard.RecommendedActions) > 0 {
		output += "ğŸ’¡ ê¶Œì¥ í–‰ë™:\n"
		for _, action := range dashboard.RecommendedActions {
			if action.Priority == "High" {
				output += fmt.Sprintf("  â€¢ %s (%s)\n", action.Action, action.Timeframe)
			}
		}
	}

	return output
}
